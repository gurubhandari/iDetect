{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os\n",
    "from string import printable\n",
    "from sklearn import model_selection\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, model_from_json, load_model\n",
    "from keras import regularizers\n",
    "from keras.layers.core import Dense, Dropout, Activation, Lambda, Flatten\n",
    "from keras.layers import Input, ELU, LSTM, Embedding, Convolution2D, MaxPooling2D, \\\n",
    "BatchNormalization, Convolution1D, MaxPooling1D, concatenate\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Deep Learning \n",
    "\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- tensorflow 1.4.1\n",
    "- keras 2.1.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>isMalicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>( lowpan1 -&gt; addr1  [ 0 ]    ==  prefixBuffer1...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>staticvoid goodB2G2  (  )    {  char * data ; ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>printf  (  \" valeur entree: %lu\\n \"  ,  ent_ul...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>staticvoid good1  (  )    {  while  ( 1 )   { ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3694</th>\n",
       "      <td>staticvoid good1  (  )    {  if   ( staticFals...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   code  isMalicious\n",
       "571   ( lowpan1 -> addr1  [ 0 ]    ==  prefixBuffer1...           16\n",
       "3410  staticvoid goodB2G2  (  )    {  char * data ; ...            0\n",
       "883   printf  (  \" valeur entree: %lu\\n \"  ,  ent_ul...           28\n",
       "3474  staticvoid good1  (  )    {  while  ( 1 )   { ...            0\n",
       "3694  staticvoid good1  (  )    {  if   ( staticFals...            0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load data code_snippet\n",
    "DATA_HOME = 'DL/'\n",
    "Final_Labeled_Dataset = pd.read_csv('Dataset of IoT OSs code - training.csv', encoding= 'unicode_escape')\n",
    "Final_Labeled_Dataset.sample(n=5).head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3708, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Labeled_Dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>isMalicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>printf  (  \" %d\\n \"  ,  ent_dec_neg )  ;</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>atoi(argv[2])</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>staticvoid goodB2G1  (  )    {  char * data ; ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>ImmutableString move  =  std::move  ( copy )  ...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>staticvoid good2  (  )    {  if   ( stATIC_CON...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   code  isMalicious\n",
       "877            printf  (  \" %d\\n \"  ,  ent_dec_neg )  ;           28\n",
       "1705                                      atoi(argv[2])           20\n",
       "3099  staticvoid goodB2G1  (  )    {  char * data ; ...            0\n",
       "979   ImmutableString move  =  std::move  ( copy )  ...           32\n",
       "1997  staticvoid good2  (  )    {  if   ( stATIC_CON...            0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Labeled_Dataset.dropna(inplace=True)\n",
    "Final_Labeled_Dataset.drop_duplicates(inplace=True)\n",
    "Final_Labeled_Dataset.sample(n=5).head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3255, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Labeled_Dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix dimensions of X:  (3255, 150) Vector dimension of target:  (3255,)\n"
     ]
    }
   ],
   "source": [
    "code_snippet_int_tokens = [[printable.index(x) + 1 for x in code_snippet if x in printable] \n",
    "                           for code_snippet in Final_Labeled_Dataset.code]\n",
    "max_len = 150\n",
    "X = sequence.pad_sequences(code_snippet_int_tokens, maxlen=max_len)\n",
    "target = np.array (Final_Labeled_Dataset.isMalicious)\n",
    "print('Matrix dimensions of X: ', X.shape, 'Vector dimension of target: ', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Cross-Validation: Split the data set into training and test data\n",
    "X_train, X_test, target_train, target_test = model_selection.train_test_split(X, target, test_size=0.30, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GENERAL get layer dimensions for any model!\n",
    "def print_layers_dims(model):\n",
    "    l_layers = model.layers\n",
    "    # Note None is ALWAYS batch_size\n",
    "    for i in range(len(l_layers)):\n",
    "        print(l_layers[i])\n",
    "        print('Input Shape: ', l_layers[i].input_shape, 'Output Shape: ', l_layers[i].output_shape)\n",
    "\n",
    "# GENERAL save model to disk function!\n",
    "def save_model(fileModelJSON,fileWeights):\n",
    "    #print(\"Saving model to disk: \",fileModelJSON,\"and\",fileWeights)\n",
    "    #have h5py installed\n",
    "    if Path(fileModelJSON).is_file():\n",
    "        os.remove(fileModelJSON)\n",
    "    json_string = model.to_json()\n",
    "    with open(fileModelJSON,'w' ) as f:\n",
    "        json.dump(json_string, f)\n",
    "    if Path(fileWeights).is_file():\n",
    "        os.remove(fileWeights)\n",
    "    model.save_weights(fileWeights)\n",
    "    \n",
    "\n",
    "# GENERAL load model from disk function!\n",
    "def load_model(fileModelJSON,fileWeights):\n",
    "    #print(\"Saving model to disk: \",fileModelJSON,\"and\",fileWeights)\n",
    "    with open(fileModelJSON, 'r') as f:\n",
    "         model_json = json.load(f)\n",
    "         model = model_from_json(model_json)\n",
    "    \n",
    "    model.load_weights(fileWeights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model 2 - 1D Convolutions and Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(max_len=150, emb_dim=32, max_vocab_len=150, W_reg=regularizers.l2(1e-4)):\n",
    "    # Input\n",
    "    main_input = Input(shape=(max_len,), dtype='int32', name='main_input')\n",
    "    # Embedding layer\n",
    "    emb = Embedding(input_dim=max_vocab_len, output_dim=emb_dim, input_length=max_len,\n",
    "                W_regularizer=W_reg)(main_input) \n",
    "    emb = Dropout(0.25)(emb)\n",
    "\n",
    "    \n",
    "    def sum_1d(X):\n",
    "        return K.sum(X, axis=1)\n",
    "    \n",
    "    def get_conv_layer(emb, kernel_size=5, filters=256):\n",
    "        # Conv layer\n",
    "        conv = Convolution1D(kernel_size=kernel_size, filters=filters, \\\n",
    "                     border_mode='same')(emb)\n",
    "        conv = ELU()(conv)\n",
    "\n",
    "        conv = Lambda(sum_1d, output_shape=(filters,))(conv)\n",
    "        #conv = BatchNormalization(mode=0)(conv)\n",
    "        conv = Dropout(0.5)(conv)\n",
    "        return conv\n",
    "    \n",
    "        # Multiple Conv Layers\n",
    "    # calling custom conv function from above\n",
    "    conv1 = get_conv_layer(emb, kernel_size=2, filters=256)\n",
    "    conv2 = get_conv_layer(emb, kernel_size=3, filters=256)\n",
    "    conv3 = get_conv_layer(emb, kernel_size=4, filters=256)\n",
    "    conv4 = get_conv_layer(emb, kernel_size=5, filters=256)\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    merged = concatenate([conv1,conv2,conv3,conv4], axis=1)\n",
    "\n",
    "    hidden1 = Dense(1024)(merged)\n",
    "    hidden1 = ELU()(hidden1)\n",
    "    hidden1 = BatchNormalization(mode=0)(hidden1)\n",
    "    hidden1 = Dropout(0.5)(hidden1)\n",
    "\n",
    "    hidden2 = Dense(1024)(hidden1)\n",
    "    hidden2 = ELU()(hidden2)\n",
    "    hidden2 = BatchNormalization(mode=0)(hidden2)\n",
    "    hidden2 = Dropout(0.5)(hidden2)\n",
    "      \n",
    "        # Output layer (last fully connected layer)\n",
    "    output = Dense(55, activation='sigmoid', name='output')(hidden2)\n",
    "    \n",
    "        # Compile model and define optimizer\n",
    "    model = Model(input=[main_input], output=[output])\n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 150, 32)      4800        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 150, 32)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 150, 256)     16640       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 150, 256)     24832       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 150, 256)     33024       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 150, 256)     41216       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 150, 256)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_2 (ELU)                     (None, 150, 256)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 150, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_4 (ELU)                     (None, 150, 256)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 256)          0           elu_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 256)          0           elu_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 256)          0           elu_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 256)          0           elu_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1049600     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "elu_5 (ELU)                     (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024)         4096        elu_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         1049600     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_6 (ELU)                     (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1024)         4096        elu_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1024)         0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 55)           56375       dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,284,279\n",
      "Trainable params: 2,280,183\n",
      "Non-trainable params: 4,096\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "2278/2278 [==============================] - 7s 3ms/step - loss: 3.8554 - acc: 0.2796\n",
      "Epoch 2/800\n",
      "2278/2278 [==============================] - 7s 3ms/step - loss: 3.5766 - acc: 0.3600\n",
      "Epoch 3/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 3.3628 - acc: 0.4109\n",
      "Epoch 4/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 3.0853 - acc: 0.4627\n",
      "Epoch 5/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.7335 - acc: 0.4741\n",
      "Epoch 6/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.5255 - acc: 0.4750\n",
      "Epoch 7/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.4053 - acc: 0.4789\n",
      "Epoch 8/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.3484 - acc: 0.4838\n",
      "Epoch 9/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.3214 - acc: 0.4807\n",
      "Epoch 10/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.2619 - acc: 0.4824\n",
      "Epoch 11/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.2106 - acc: 0.4794\n",
      "Epoch 12/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.1948 - acc: 0.4930\n",
      "Epoch 13/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.1802 - acc: 0.4873\n",
      "Epoch 14/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.1535 - acc: 0.4855\n",
      "Epoch 15/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.1097 - acc: 0.4824\n",
      "Epoch 16/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.1106 - acc: 0.4960\n",
      "Epoch 17/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.0859 - acc: 0.5018\n",
      "Epoch 18/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.0508 - acc: 0.5048\n",
      "Epoch 19/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 2.0471 - acc: 0.5097\n",
      "Epoch 20/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 2.0203 - acc: 0.5123\n",
      "Epoch 21/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 2.0194 - acc: 0.5136\n",
      "Epoch 22/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.9944 - acc: 0.5075\n",
      "Epoch 23/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.9876 - acc: 0.5136\n",
      "Epoch 24/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 2.0099 - acc: 0.5154\n",
      "Epoch 25/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.9340 - acc: 0.5246\n",
      "Epoch 26/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.9470 - acc: 0.5233\n",
      "Epoch 27/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.9117 - acc: 0.5303\n",
      "Epoch 28/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.9073 - acc: 0.5351\n",
      "Epoch 29/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.8893 - acc: 0.5325\n",
      "Epoch 30/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.8779 - acc: 0.5303\n",
      "Epoch 31/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.8874 - acc: 0.5369\n",
      "Epoch 32/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.8559 - acc: 0.5435\n",
      "Epoch 33/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.8768 - acc: 0.5342\n",
      "Epoch 34/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.8438 - acc: 0.5461\n",
      "Epoch 35/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.8269 - acc: 0.5443\n",
      "Epoch 36/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.8399 - acc: 0.5439\n",
      "Epoch 37/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.8187 - acc: 0.5505\n",
      "Epoch 38/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.8109 - acc: 0.5457\n",
      "Epoch 39/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.7828 - acc: 0.5522\n",
      "Epoch 40/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.8046 - acc: 0.5593\n",
      "Epoch 41/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.8128 - acc: 0.5571\n",
      "Epoch 42/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.7394 - acc: 0.5610\n",
      "Epoch 43/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.7356 - acc: 0.5689\n",
      "Epoch 44/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.7577 - acc: 0.5628\n",
      "Epoch 45/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.7383 - acc: 0.5658\n",
      "Epoch 46/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.7491 - acc: 0.5632\n",
      "Epoch 47/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.7189 - acc: 0.5650\n",
      "Epoch 48/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.7314 - acc: 0.5724\n",
      "Epoch 49/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.7032 - acc: 0.5755\n",
      "Epoch 50/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.7134 - acc: 0.5812\n",
      "Epoch 51/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 1.6876 - acc: 0.5790\n",
      "Epoch 52/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.6621 - acc: 0.5812\n",
      "Epoch 53/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.6679 - acc: 0.5865\n",
      "Epoch 54/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 1.6608 - acc: 0.5847\n",
      "Epoch 55/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.6643 - acc: 0.5900\n",
      "Epoch 56/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.6531 - acc: 0.5878\n",
      "Epoch 57/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.6248 - acc: 0.5957\n",
      "Epoch 58/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.6339 - acc: 0.5961\n",
      "Epoch 59/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 1.6163 - acc: 0.5882\n",
      "Epoch 60/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.6363 - acc: 0.5957\n",
      "Epoch 61/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.5965 - acc: 0.5957\n",
      "Epoch 62/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.6221 - acc: 0.5917\n",
      "Epoch 63/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.6240 - acc: 0.5904\n",
      "Epoch 64/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 1.5959 - acc: 0.5961\n",
      "Epoch 65/800\n",
      "2278/2278 [==============================] - 8s 3ms/step - loss: 1.5799 - acc: 0.6014\n",
      "Epoch 66/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.5734 - acc: 0.6071\n",
      "Epoch 67/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.5805 - acc: 0.6119\n",
      "Epoch 68/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.5580 - acc: 0.6054\n",
      "Epoch 69/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.5781 - acc: 0.6119\n",
      "Epoch 70/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.5341 - acc: 0.6010\n",
      "Epoch 71/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.5542 - acc: 0.6124\n",
      "Epoch 72/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.5366 - acc: 0.6106\n",
      "Epoch 73/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 1.5308 - acc: 0.6102\n",
      "Epoch 74/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.5282 - acc: 0.6071\n",
      "Epoch 75/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.5280 - acc: 0.6155\n",
      "Epoch 76/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.5231 - acc: 0.6190\n",
      "Epoch 77/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.5158 - acc: 0.6097\n",
      "Epoch 78/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.4874 - acc: 0.6128\n",
      "Epoch 79/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.4986 - acc: 0.6190\n",
      "Epoch 80/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.4784 - acc: 0.6172\n",
      "Epoch 81/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.4861 - acc: 0.6194\n",
      "Epoch 82/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.4835 - acc: 0.6185\n",
      "Epoch 83/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2278/2278 [==============================] - 11s 5ms/step - loss: 1.4839 - acc: 0.6242\n",
      "Epoch 84/800\n",
      "2278/2278 [==============================] - 8s 3ms/step - loss: 1.4534 - acc: 0.6247A:\n",
      "Epoch 85/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.4605 - acc: 0.6216\n",
      "Epoch 86/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.4534 - acc: 0.6286\n",
      "Epoch 87/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.4257 - acc: 0.6317\n",
      "Epoch 88/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 1.4072 - acc: 0.6308\n",
      "Epoch 89/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.4015 - acc: 0.6326\n",
      "Epoch 90/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.4218 - acc: 0.6295\n",
      "Epoch 91/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.4076 - acc: 0.6396\n",
      "Epoch 92/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.4070 - acc: 0.6374\n",
      "Epoch 93/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.3928 - acc: 0.6409\n",
      "Epoch 94/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.3829 - acc: 0.6427\n",
      "Epoch 95/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 1.3651 - acc: 0.6514\n",
      "Epoch 96/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.3765 - acc: 0.6493A: 4s -\n",
      "Epoch 97/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.3716 - acc: 0.6479\n",
      "Epoch 98/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.3917 - acc: 0.6484\n",
      "Epoch 99/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.3556 - acc: 0.6629\n",
      "Epoch 100/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 1.3689 - acc: 0.6510\n",
      "Epoch 101/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.3436 - acc: 0.6536\n",
      "Epoch 102/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.3408 - acc: 0.6585\n",
      "Epoch 103/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.3571 - acc: 0.6471\n",
      "Epoch 104/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.3340 - acc: 0.6589\n",
      "Epoch 105/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.3457 - acc: 0.6427\n",
      "Epoch 106/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.3318 - acc: 0.6550\n",
      "Epoch 107/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.3050 - acc: 0.6620\n",
      "Epoch 108/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.3169 - acc: 0.6681\n",
      "Epoch 109/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.3071 - acc: 0.6716\n",
      "Epoch 110/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.2944 - acc: 0.6738\n",
      "Epoch 111/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.2984 - acc: 0.6655\n",
      "Epoch 112/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 1.3033 - acc: 0.6642\n",
      "Epoch 113/800\n",
      "2278/2278 [==============================] - 8s 3ms/step - loss: 1.3002 - acc: 0.6664\n",
      "Epoch 114/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.2879 - acc: 0.6681\n",
      "Epoch 115/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.2698 - acc: 0.6738\n",
      "Epoch 116/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.2438 - acc: 0.6778\n",
      "Epoch 117/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.2483 - acc: 0.6831\n",
      "Epoch 118/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.2532 - acc: 0.6773\n",
      "Epoch 119/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 1.2620 - acc: 0.6712\n",
      "Epoch 120/800\n",
      "2278/2278 [==============================] - 8s 3ms/step - loss: 1.2428 - acc: 0.6778\n",
      "Epoch 121/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.2496 - acc: 0.6725\n",
      "Epoch 122/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.2221 - acc: 0.6817\n",
      "Epoch 123/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.2209 - acc: 0.6883\n",
      "Epoch 124/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 1.2431 - acc: 0.6817\n",
      "Epoch 125/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.2325 - acc: 0.6747\n",
      "Epoch 126/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.2326 - acc: 0.6870\n",
      "Epoch 127/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.2045 - acc: 0.6813\n",
      "Epoch 128/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.1997 - acc: 0.6927\n",
      "Epoch 129/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.1921 - acc: 0.6883\n",
      "Epoch 130/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.2043 - acc: 0.6927\n",
      "Epoch 131/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 1.1758 - acc: 0.6940\n",
      "Epoch 132/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.1794 - acc: 0.6905\n",
      "Epoch 133/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 1.2012 - acc: 0.6958\n",
      "Epoch 134/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.1563 - acc: 0.6967\n",
      "Epoch 135/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.1851 - acc: 0.6883\n",
      "Epoch 136/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.1525 - acc: 0.7050\n",
      "Epoch 137/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.1762 - acc: 0.6997\n",
      "Epoch 138/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 1.1503 - acc: 0.7032\n",
      "Epoch 139/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.1464 - acc: 0.7041\n",
      "Epoch 140/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.1636 - acc: 0.7019\n",
      "Epoch 141/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.1485 - acc: 0.6971\n",
      "Epoch 142/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.1266 - acc: 0.7050\n",
      "Epoch 143/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 1.1126 - acc: 0.7120\n",
      "Epoch 144/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.1220 - acc: 0.7068\n",
      "Epoch 145/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.1398 - acc: 0.6993\n",
      "Epoch 146/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.1275 - acc: 0.7068\n",
      "Epoch 147/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.1128 - acc: 0.7125\n",
      "Epoch 148/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.0945 - acc: 0.7107\n",
      "Epoch 149/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.1314 - acc: 0.7138\n",
      "Epoch 150/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 1.0967 - acc: 0.7169\n",
      "Epoch 151/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.0996 - acc: 0.7112\n",
      "Epoch 152/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.0693 - acc: 0.7221\n",
      "Epoch 153/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.0766 - acc: 0.7169\n",
      "Epoch 154/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.0771 - acc: 0.7256\n",
      "Epoch 155/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.0546 - acc: 0.7252\n",
      "Epoch 156/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.0732 - acc: 0.7155\n",
      "Epoch 157/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 1.0344 - acc: 0.7353\n",
      "Epoch 158/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.0653 - acc: 0.7164\n",
      "Epoch 159/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.0602 - acc: 0.7125\n",
      "Epoch 160/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.0620 - acc: 0.7256\n",
      "Epoch 161/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.0541 - acc: 0.7243\n",
      "Epoch 162/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.0513 - acc: 0.7230\n",
      "Epoch 163/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 1.0254 - acc: 0.7379\n",
      "Epoch 164/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2278/2278 [==============================] - 10s 4ms/step - loss: 1.0034 - acc: 0.7344\n",
      "Epoch 165/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.9925 - acc: 0.7414\n",
      "Epoch 166/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.0036 - acc: 0.7335\n",
      "Epoch 167/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 1.0292 - acc: 0.7414\n",
      "Epoch 168/800\n",
      "2278/2278 [==============================] - 8s 3ms/step - loss: 1.0224 - acc: 0.7309\n",
      "Epoch 169/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.9911 - acc: 0.7335\n",
      "Epoch 170/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 1.0008 - acc: 0.7362\n",
      "Epoch 171/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.9977 - acc: 0.7327\n",
      "Epoch 172/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.9992 - acc: 0.7419\n",
      "Epoch 173/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.9592 - acc: 0.7471\n",
      "Epoch 174/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.9863 - acc: 0.7388\n",
      "Epoch 175/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.9742 - acc: 0.7445\n",
      "Epoch 176/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.9786 - acc: 0.7436\n",
      "Epoch 177/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.9531 - acc: 0.7559\n",
      "Epoch 178/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.9462 - acc: 0.7480\n",
      "Epoch 179/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.9348 - acc: 0.7572\n",
      "Epoch 180/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.9225 - acc: 0.7476\n",
      "Epoch 181/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.9451 - acc: 0.7432\n",
      "Epoch 182/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.9193 - acc: 0.7572\n",
      "Epoch 183/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.9305 - acc: 0.7568\n",
      "Epoch 184/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.9332 - acc: 0.7590\n",
      "Epoch 185/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.9035 - acc: 0.7757\n",
      "Epoch 186/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.9326 - acc: 0.7511\n",
      "Epoch 187/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.9055 - acc: 0.7660\n",
      "Epoch 188/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.9154 - acc: 0.7608\n",
      "Epoch 189/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.8800 - acc: 0.7682\n",
      "Epoch 190/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.9031 - acc: 0.7643\n",
      "Epoch 191/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.8940 - acc: 0.7572\n",
      "Epoch 192/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.8897 - acc: 0.7687\n",
      "Epoch 193/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.8663 - acc: 0.7687\n",
      "Epoch 194/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.8678 - acc: 0.7744\n",
      "Epoch 195/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.8676 - acc: 0.7665\n",
      "Epoch 196/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.8980 - acc: 0.7603\n",
      "Epoch 197/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.8590 - acc: 0.7761\n",
      "Epoch 198/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.8500 - acc: 0.7744\n",
      "Epoch 199/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.8727 - acc: 0.7722\n",
      "Epoch 200/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.8451 - acc: 0.7796\n",
      "Epoch 201/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.8521 - acc: 0.7744\n",
      "Epoch 202/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.8426 - acc: 0.7796\n",
      "Epoch 203/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.8282 - acc: 0.7783\n",
      "Epoch 204/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.8495 - acc: 0.7744\n",
      "Epoch 205/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.8296 - acc: 0.7783\n",
      "Epoch 206/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.8233 - acc: 0.7845\n",
      "Epoch 207/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.8296 - acc: 0.7845\n",
      "Epoch 208/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.7858 - acc: 0.7941\n",
      "Epoch 209/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.8131 - acc: 0.7827\n",
      "Epoch 210/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.8102 - acc: 0.7880: 1s - loss: 0.8150 - acc: 0.\n",
      "Epoch 211/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.8374 - acc: 0.7752\n",
      "Epoch 212/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.8050 - acc: 0.7902\n",
      "Epoch 213/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.8031 - acc: 0.7880\n",
      "Epoch 214/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.7800 - acc: 0.7823\n",
      "Epoch 215/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.7882 - acc: 0.7788\n",
      "Epoch 216/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.7990 - acc: 0.7893\n",
      "Epoch 217/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.7800 - acc: 0.7963\n",
      "Epoch 218/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.7526 - acc: 0.8033\n",
      "Epoch 219/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.7944 - acc: 0.7858\n",
      "Epoch 220/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.7381 - acc: 0.8003\n",
      "Epoch 221/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.7500 - acc: 0.7932\n",
      "Epoch 222/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.7366 - acc: 0.8007\n",
      "Epoch 223/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.7567 - acc: 0.7994\n",
      "Epoch 224/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.7577 - acc: 0.7910\n",
      "Epoch 225/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.7406 - acc: 0.8042\n",
      "Epoch 226/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.7491 - acc: 0.7989\n",
      "Epoch 227/800\n",
      "2278/2278 [==============================] - ETA: 0s - loss: 0.7430 - acc: 0.802 - 11s 5ms/step - loss: 0.7425 - acc: 0.8020\n",
      "Epoch 228/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.7411 - acc: 0.8051\n",
      "Epoch 229/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.7399 - acc: 0.7994\n",
      "Epoch 230/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.7337 - acc: 0.7972\n",
      "Epoch 231/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.7387 - acc: 0.7946\n",
      "Epoch 232/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.7095 - acc: 0.8064\n",
      "Epoch 233/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.7249 - acc: 0.8068\n",
      "Epoch 234/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.7004 - acc: 0.8112\n",
      "Epoch 235/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.6979 - acc: 0.8121\n",
      "Epoch 236/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.7113 - acc: 0.8077\n",
      "Epoch 237/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.7003 - acc: 0.8086\n",
      "Epoch 238/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.7072 - acc: 0.8020\n",
      "Epoch 239/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.7337 - acc: 0.8051\n",
      "Epoch 240/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.6884 - acc: 0.8222: 1s - loss: 0.6916 - acc: 0.8 - ETA: 0s - loss: 0.6862 - acc: 0.82\n",
      "Epoch 241/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.6742 - acc: 0.8130\n",
      "Epoch 242/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.6941 - acc: 0.8161\n",
      "Epoch 243/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.7171 - acc: 0.8068\n",
      "Epoch 244/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.6900 - acc: 0.8121\n",
      "Epoch 245/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.6706 - acc: 0.8161\n",
      "Epoch 246/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.6611 - acc: 0.8227\n",
      "Epoch 247/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.6878 - acc: 0.8156\n",
      "Epoch 248/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.6567 - acc: 0.8169\n",
      "Epoch 249/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.6120 - acc: 0.8266\n",
      "Epoch 250/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.6601 - acc: 0.8187\n",
      "Epoch 251/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.6360 - acc: 0.8279\n",
      "Epoch 252/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.6867 - acc: 0.8178\n",
      "Epoch 253/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.6410 - acc: 0.8253\n",
      "Epoch 254/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.6337 - acc: 0.8288\n",
      "Epoch 255/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.5990 - acc: 0.8323\n",
      "Epoch 256/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.6317 - acc: 0.8257\n",
      "Epoch 257/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.6049 - acc: 0.8327\n",
      "Epoch 258/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.6045 - acc: 0.8310\n",
      "Epoch 259/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.6282 - acc: 0.8297\n",
      "Epoch 260/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.5948 - acc: 0.8284\n",
      "Epoch 261/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.6098 - acc: 0.8336\n",
      "Epoch 262/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.6168 - acc: 0.8297\n",
      "Epoch 263/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.5874 - acc: 0.8420\n",
      "Epoch 264/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.6029 - acc: 0.8336\n",
      "Epoch 265/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.6235 - acc: 0.8270\n",
      "Epoch 266/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.5498 - acc: 0.8468\n",
      "Epoch 267/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.5933 - acc: 0.8345\n",
      "Epoch 268/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.6180 - acc: 0.8332\n",
      "Epoch 269/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.5811 - acc: 0.8389\n",
      "Epoch 270/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.5881 - acc: 0.8306\n",
      "Epoch 271/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.5981 - acc: 0.8341\n",
      "Epoch 272/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.5935 - acc: 0.8301\n",
      "Epoch 273/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.5635 - acc: 0.8503\n",
      "Epoch 274/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.5991 - acc: 0.8367\n",
      "Epoch 275/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.5743 - acc: 0.8389\n",
      "Epoch 276/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.5662 - acc: 0.8371\n",
      "Epoch 277/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.5739 - acc: 0.8380\n",
      "Epoch 278/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.5658 - acc: 0.8376\n",
      "Epoch 279/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.5539 - acc: 0.8450\n",
      "Epoch 280/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.5749 - acc: 0.8477\n",
      "Epoch 281/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.5616 - acc: 0.8437\n",
      "Epoch 282/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.5598 - acc: 0.8376\n",
      "Epoch 283/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.5892 - acc: 0.8301\n",
      "Epoch 284/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.5274 - acc: 0.8494\n",
      "Epoch 285/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.5361 - acc: 0.8472\n",
      "Epoch 286/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.5586 - acc: 0.8446\n",
      "Epoch 287/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.5540 - acc: 0.8398\n",
      "Epoch 288/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.5441 - acc: 0.8538\n",
      "Epoch 289/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.5305 - acc: 0.8582\n",
      "Epoch 290/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.5440 - acc: 0.8556\n",
      "Epoch 291/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.5153 - acc: 0.8578\n",
      "Epoch 292/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.5559 - acc: 0.8385\n",
      "Epoch 293/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.5127 - acc: 0.8507\n",
      "Epoch 294/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.5165 - acc: 0.8595\n",
      "Epoch 295/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.5031 - acc: 0.8565\n",
      "Epoch 296/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.5010 - acc: 0.8551\n",
      "Epoch 297/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.5410 - acc: 0.8464\n",
      "Epoch 298/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.5209 - acc: 0.8481\n",
      "Epoch 299/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.5056 - acc: 0.8617\n",
      "Epoch 300/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.5092 - acc: 0.8538\n",
      "Epoch 301/800\n",
      "2278/2278 [==============================] - ETA: 0s - loss: 0.5067 - acc: 0.857 - 9s 4ms/step - loss: 0.5109 - acc: 0.8556\n",
      "Epoch 302/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4917 - acc: 0.8613\n",
      "Epoch 303/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.5079 - acc: 0.8586\n",
      "Epoch 304/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.4990 - acc: 0.8586\n",
      "Epoch 305/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.5105 - acc: 0.8626\n",
      "Epoch 306/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.5186 - acc: 0.8560\n",
      "Epoch 307/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4942 - acc: 0.8560\n",
      "Epoch 308/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4926 - acc: 0.8565\n",
      "Epoch 309/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.5050 - acc: 0.8591\n",
      "Epoch 310/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4923 - acc: 0.8600\n",
      "Epoch 311/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.5065 - acc: 0.8652\n",
      "Epoch 312/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4939 - acc: 0.8639\n",
      "Epoch 313/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4957 - acc: 0.8630\n",
      "Epoch 314/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.5466 - acc: 0.8534\n",
      "Epoch 315/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4845 - acc: 0.8604\n",
      "Epoch 316/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4877 - acc: 0.8639\n",
      "Epoch 317/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.4689 - acc: 0.8661\n",
      "Epoch 318/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.5027 - acc: 0.8560\n",
      "Epoch 319/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4730 - acc: 0.8723\n",
      "Epoch 320/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.5122 - acc: 0.8613\n",
      "Epoch 321/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4581 - acc: 0.8665\n",
      "Epoch 322/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4661 - acc: 0.8613\n",
      "Epoch 323/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.4615 - acc: 0.8727\n",
      "Epoch 324/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.4736 - acc: 0.8701\n",
      "Epoch 325/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.4688 - acc: 0.8670\n",
      "Epoch 326/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4631 - acc: 0.8714\n",
      "Epoch 327/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.5083 - acc: 0.8565\n",
      "Epoch 328/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4873 - acc: 0.8670\n",
      "Epoch 329/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4624 - acc: 0.8696\n",
      "Epoch 330/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.4378 - acc: 0.8701\n",
      "Epoch 331/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4337 - acc: 0.8793\n",
      "Epoch 332/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.4620 - acc: 0.8644\n",
      "Epoch 333/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4515 - acc: 0.8749\n",
      "Epoch 334/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4599 - acc: 0.8727\n",
      "Epoch 335/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4293 - acc: 0.8810\n",
      "Epoch 336/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.4435 - acc: 0.8762\n",
      "Epoch 337/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.4404 - acc: 0.8740\n",
      "Epoch 338/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.4929 - acc: 0.8661\n",
      "Epoch 339/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4658 - acc: 0.8753\n",
      "Epoch 340/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4320 - acc: 0.8762\n",
      "Epoch 341/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.4349 - acc: 0.8780\n",
      "Epoch 342/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.4411 - acc: 0.8687\n",
      "Epoch 343/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4291 - acc: 0.8740\n",
      "Epoch 344/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4029 - acc: 0.8828\n",
      "Epoch 345/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4579 - acc: 0.8749\n",
      "Epoch 346/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4470 - acc: 0.8771\n",
      "Epoch 347/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.4376 - acc: 0.8758\n",
      "Epoch 348/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.4159 - acc: 0.8854\n",
      "Epoch 349/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.4214 - acc: 0.8815\n",
      "Epoch 350/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4213 - acc: 0.8784\n",
      "Epoch 351/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4248 - acc: 0.8793\n",
      "Epoch 352/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4271 - acc: 0.8824\n",
      "Epoch 353/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.4240 - acc: 0.8837\n",
      "Epoch 354/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.4147 - acc: 0.8889\n",
      "Epoch 355/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4265 - acc: 0.8828\n",
      "Epoch 356/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4263 - acc: 0.8797\n",
      "Epoch 357/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4275 - acc: 0.8898\n",
      "Epoch 358/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.4127 - acc: 0.8758\n",
      "Epoch 359/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3916 - acc: 0.8832\n",
      "Epoch 360/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.4089 - acc: 0.8894\n",
      "Epoch 361/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4034 - acc: 0.8942\n",
      "Epoch 362/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4379 - acc: 0.8753\n",
      "Epoch 363/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.3841 - acc: 0.8946\n",
      "Epoch 364/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3953 - acc: 0.8859\n",
      "Epoch 365/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.3874 - acc: 0.8876\n",
      "Epoch 366/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3645 - acc: 0.8911\n",
      "Epoch 367/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4048 - acc: 0.8819: 4s - loss: 0.3745\n",
      "Epoch 368/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4166 - acc: 0.8758\n",
      "Epoch 369/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.4091 - acc: 0.8850\n",
      "Epoch 370/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.3931 - acc: 0.8859\n",
      "Epoch 371/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.4032 - acc: 0.8885\n",
      "Epoch 372/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3814 - acc: 0.8872\n",
      "Epoch 373/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.4067 - acc: 0.8850\n",
      "Epoch 374/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3719 - acc: 0.8960\n",
      "Epoch 375/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.3717 - acc: 0.8894\n",
      "Epoch 376/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3857 - acc: 0.8929\n",
      "Epoch 377/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3875 - acc: 0.8854\n",
      "Epoch 378/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3976 - acc: 0.8854\n",
      "Epoch 379/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3795 - acc: 0.8986\n",
      "Epoch 380/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.3860 - acc: 0.8832\n",
      "Epoch 381/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3910 - acc: 0.8924\n",
      "Epoch 382/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3914 - acc: 0.8903\n",
      "Epoch 383/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3818 - acc: 0.8964\n",
      "Epoch 384/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3547 - acc: 0.8982\n",
      "Epoch 385/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3658 - acc: 0.8942\n",
      "Epoch 386/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3825 - acc: 0.8859\n",
      "Epoch 387/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3704 - acc: 0.8942\n",
      "Epoch 388/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3771 - acc: 0.8907\n",
      "Epoch 389/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3656 - acc: 0.8933\n",
      "Epoch 390/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.3884 - acc: 0.8916\n",
      "Epoch 391/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3620 - acc: 0.8951\n",
      "Epoch 392/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3792 - acc: 0.8942\n",
      "Epoch 393/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3960 - acc: 0.8920\n",
      "Epoch 394/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3669 - acc: 0.8942\n",
      "Epoch 395/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3970 - acc: 0.8894\n",
      "Epoch 396/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3499 - acc: 0.8990\n",
      "Epoch 397/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.3716 - acc: 0.8894\n",
      "Epoch 398/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3579 - acc: 0.8986\n",
      "Epoch 399/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3535 - acc: 0.8977\n",
      "Epoch 400/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3704 - acc: 0.8968\n",
      "Epoch 401/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3620 - acc: 0.9025\n",
      "Epoch 402/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.3743 - acc: 0.8850\n",
      "Epoch 403/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3488 - acc: 0.8977\n",
      "Epoch 404/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3619 - acc: 0.8973\n",
      "Epoch 405/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3638 - acc: 0.8863\n",
      "Epoch 406/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3493 - acc: 0.8942\n",
      "Epoch 407/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.3723 - acc: 0.8951\n",
      "Epoch 408/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3487 - acc: 0.8951\n",
      "Epoch 409/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3465 - acc: 0.9030\n",
      "Epoch 410/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3730 - acc: 0.8872\n",
      "Epoch 411/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3512 - acc: 0.8986\n",
      "Epoch 412/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.3333 - acc: 0.9052\n",
      "Epoch 413/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3655 - acc: 0.8942\n",
      "Epoch 414/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3544 - acc: 0.8946\n",
      "Epoch 415/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3320 - acc: 0.9039\n",
      "Epoch 416/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3672 - acc: 0.8898\n",
      "Epoch 417/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3452 - acc: 0.9039\n",
      "Epoch 418/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3436 - acc: 0.9030\n",
      "Epoch 419/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.3484 - acc: 0.9069\n",
      "Epoch 420/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3145 - acc: 0.9113\n",
      "Epoch 421/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3532 - acc: 0.8999\n",
      "Epoch 422/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3345 - acc: 0.9074\n",
      "Epoch 423/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3641 - acc: 0.9008\n",
      "Epoch 424/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3385 - acc: 0.8999\n",
      "Epoch 425/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3473 - acc: 0.8942\n",
      "Epoch 426/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3314 - acc: 0.9025\n",
      "Epoch 427/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3296 - acc: 0.9017\n",
      "Epoch 428/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3602 - acc: 0.8955\n",
      "Epoch 429/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3483 - acc: 0.8982\n",
      "Epoch 430/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3496 - acc: 0.9004\n",
      "Epoch 431/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.3065 - acc: 0.9175\n",
      "Epoch 432/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3481 - acc: 0.8990\n",
      "Epoch 433/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3259 - acc: 0.9065\n",
      "Epoch 434/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3383 - acc: 0.9104\n",
      "Epoch 435/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3270 - acc: 0.9052A: 5s - loss: \n",
      "Epoch 436/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3316 - acc: 0.9039\n",
      "Epoch 437/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3488 - acc: 0.8999\n",
      "Epoch 438/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3154 - acc: 0.9100\n",
      "Epoch 439/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3158 - acc: 0.9069\n",
      "Epoch 440/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3361 - acc: 0.9004\n",
      "Epoch 441/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3232 - acc: 0.9131\n",
      "Epoch 442/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3266 - acc: 0.9030\n",
      "Epoch 443/800\n",
      "2278/2278 [==============================] - 11s 5ms/step - loss: 0.3376 - acc: 0.9069\n",
      "Epoch 444/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3250 - acc: 0.9025\n",
      "Epoch 445/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3393 - acc: 0.9039\n",
      "Epoch 446/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3186 - acc: 0.9091\n",
      "Epoch 447/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3079 - acc: 0.9131\n",
      "Epoch 448/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.3097 - acc: 0.9052\n",
      "Epoch 449/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3198 - acc: 0.8999\n",
      "Epoch 450/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3172 - acc: 0.9074\n",
      "Epoch 451/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3462 - acc: 0.9012\n",
      "Epoch 452/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3007 - acc: 0.9157\n",
      "Epoch 453/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.3087 - acc: 0.9192\n",
      "Epoch 454/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.3102 - acc: 0.9074\n",
      "Epoch 455/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.3260 - acc: 0.9030\n",
      "Epoch 456/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3025 - acc: 0.9122\n",
      "Epoch 457/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3220 - acc: 0.9104\n",
      "Epoch 458/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3224 - acc: 0.9083\n",
      "Epoch 459/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2986 - acc: 0.9153\n",
      "Epoch 460/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3128 - acc: 0.9083\n",
      "Epoch 461/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.2876 - acc: 0.9214\n",
      "Epoch 462/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3088 - acc: 0.9175\n",
      "Epoch 463/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3082 - acc: 0.9091\n",
      "Epoch 464/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2949 - acc: 0.9236\n",
      "Epoch 465/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3067 - acc: 0.9069\n",
      "Epoch 466/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.2848 - acc: 0.9192\n",
      "Epoch 467/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3030 - acc: 0.9205\n",
      "Epoch 468/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.3020 - acc: 0.9135\n",
      "Epoch 469/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.3058 - acc: 0.9113\n",
      "Epoch 470/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2824 - acc: 0.9162\n",
      "Epoch 471/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2843 - acc: 0.9148\n",
      "Epoch 472/800\n",
      "2278/2278 [==============================] - 10s 5ms/step - loss: 0.2744 - acc: 0.9201\n",
      "Epoch 473/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.2894 - acc: 0.9192\n",
      "Epoch 474/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.2881 - acc: 0.9140\n",
      "Epoch 475/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2823 - acc: 0.9118\n",
      "Epoch 476/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2788 - acc: 0.9109\n",
      "Epoch 477/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.2620 - acc: 0.9258\n",
      "Epoch 478/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.2866 - acc: 0.9153\n",
      "Epoch 479/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.2784 - acc: 0.9162\n",
      "Epoch 480/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.2767 - acc: 0.9188\n",
      "Epoch 481/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2980 - acc: 0.9148\n",
      "Epoch 482/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2725 - acc: 0.9192\n",
      "Epoch 483/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2797 - acc: 0.9197\n",
      "Epoch 484/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.2840 - acc: 0.9175\n",
      "Epoch 485/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.2803 - acc: 0.9188\n",
      "Epoch 486/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.2886 - acc: 0.9254\n",
      "Epoch 487/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.2413 - acc: 0.9315\n",
      "Epoch 488/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2544 - acc: 0.9214\n",
      "Epoch 489/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2656 - acc: 0.9271\n",
      "Epoch 490/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2638 - acc: 0.9197\n",
      "Epoch 491/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.2600 - acc: 0.9179\n",
      "Epoch 492/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.2477 - acc: 0.9267\n",
      "Epoch 493/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.2431 - acc: 0.9280\n",
      "Epoch 494/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.2560 - acc: 0.9254\n",
      "Epoch 495/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2551 - acc: 0.9210\n",
      "Epoch 496/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2343 - acc: 0.9350\n",
      "Epoch 497/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2574 - acc: 0.9254\n",
      "Epoch 498/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2409 - acc: 0.9236\n",
      "Epoch 499/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2461 - acc: 0.9210\n",
      "Epoch 500/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.2353 - acc: 0.9280\n",
      "Epoch 501/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.2347 - acc: 0.9306\n",
      "Epoch 502/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2184 - acc: 0.9289\n",
      "Epoch 503/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2267 - acc: 0.9324\n",
      "Epoch 504/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2349 - acc: 0.9263\n",
      "Epoch 505/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2272 - acc: 0.9236\n",
      "Epoch 506/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2135 - acc: 0.9337\n",
      "Epoch 507/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2413 - acc: 0.9254\n",
      "Epoch 508/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2056 - acc: 0.9394\n",
      "Epoch 509/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2418 - acc: 0.9249\n",
      "Epoch 510/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.2374 - acc: 0.9263\n",
      "Epoch 511/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2084 - acc: 0.9258\n",
      "Epoch 512/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2233 - acc: 0.9298\n",
      "Epoch 513/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2393 - acc: 0.9263\n",
      "Epoch 514/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2034 - acc: 0.9381\n",
      "Epoch 515/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1974 - acc: 0.9363\n",
      "Epoch 516/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.2120 - acc: 0.9258\n",
      "Epoch 517/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1986 - acc: 0.9315\n",
      "Epoch 518/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2048 - acc: 0.9320\n",
      "Epoch 519/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2192 - acc: 0.9258\n",
      "Epoch 520/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1954 - acc: 0.9368\n",
      "Epoch 521/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2168 - acc: 0.9254\n",
      "Epoch 522/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2012 - acc: 0.9377\n",
      "Epoch 523/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2181 - acc: 0.9267\n",
      "Epoch 524/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2153 - acc: 0.9328\n",
      "Epoch 525/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1973 - acc: 0.9306\n",
      "Epoch 526/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2098 - acc: 0.9267\n",
      "Epoch 527/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1907 - acc: 0.9412\n",
      "Epoch 528/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.2305 - acc: 0.9289\n",
      "Epoch 529/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2080 - acc: 0.9289\n",
      "Epoch 530/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2061 - acc: 0.9324\n",
      "Epoch 531/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1980 - acc: 0.9390\n",
      "Epoch 532/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2165 - acc: 0.9311\n",
      "Epoch 533/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1751 - acc: 0.9442\n",
      "Epoch 534/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2057 - acc: 0.9328\n",
      "Epoch 535/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1973 - acc: 0.9403\n",
      "Epoch 536/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2062 - acc: 0.9355\n",
      "Epoch 537/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.2133 - acc: 0.9399\n",
      "Epoch 538/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1867 - acc: 0.9385\n",
      "Epoch 539/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1792 - acc: 0.9456\n",
      "Epoch 540/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1966 - acc: 0.9385\n",
      "Epoch 541/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2058 - acc: 0.9289\n",
      "Epoch 542/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1927 - acc: 0.9302\n",
      "Epoch 543/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1811 - acc: 0.9460\n",
      "Epoch 544/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1847 - acc: 0.9407\n",
      "Epoch 545/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1831 - acc: 0.9425\n",
      "Epoch 546/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1801 - acc: 0.9442\n",
      "Epoch 547/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1787 - acc: 0.9425\n",
      "Epoch 548/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1890 - acc: 0.9368\n",
      "Epoch 549/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1865 - acc: 0.9381\n",
      "Epoch 550/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1946 - acc: 0.9390\n",
      "Epoch 551/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1804 - acc: 0.9442\n",
      "Epoch 552/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1962 - acc: 0.9298\n",
      "Epoch 553/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1960 - acc: 0.9315\n",
      "Epoch 554/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1857 - acc: 0.9381\n",
      "Epoch 555/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1968 - acc: 0.9363\n",
      "Epoch 556/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1888 - acc: 0.9306\n",
      "Epoch 557/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1875 - acc: 0.9390\n",
      "Epoch 558/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1736 - acc: 0.9368\n",
      "Epoch 559/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1653 - acc: 0.9504\n",
      "Epoch 560/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1673 - acc: 0.9451\n",
      "Epoch 561/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1820 - acc: 0.9363\n",
      "Epoch 562/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1796 - acc: 0.9416\n",
      "Epoch 563/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1771 - acc: 0.9416\n",
      "Epoch 564/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1741 - acc: 0.9425\n",
      "Epoch 565/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1786 - acc: 0.9469\n",
      "Epoch 566/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1653 - acc: 0.9425\n",
      "Epoch 567/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.2009 - acc: 0.9368\n",
      "Epoch 568/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1713 - acc: 0.9447\n",
      "Epoch 569/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1640 - acc: 0.9500\n",
      "Epoch 570/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1765 - acc: 0.9478\n",
      "Epoch 571/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1692 - acc: 0.9403\n",
      "Epoch 572/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1714 - acc: 0.9460\n",
      "Epoch 573/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1657 - acc: 0.9500\n",
      "Epoch 574/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1623 - acc: 0.9473\n",
      "Epoch 575/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1549 - acc: 0.9513\n",
      "Epoch 576/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1798 - acc: 0.9438\n",
      "Epoch 577/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1507 - acc: 0.9548\n",
      "Epoch 578/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1883 - acc: 0.9407\n",
      "Epoch 579/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1849 - acc: 0.9421\n",
      "Epoch 580/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1793 - acc: 0.9464\n",
      "Epoch 581/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1720 - acc: 0.9412\n",
      "Epoch 582/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1721 - acc: 0.9416\n",
      "Epoch 583/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1638 - acc: 0.9464\n",
      "Epoch 584/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1774 - acc: 0.9412\n",
      "Epoch 585/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1719 - acc: 0.9469\n",
      "Epoch 586/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1696 - acc: 0.9447\n",
      "Epoch 587/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1735 - acc: 0.9421\n",
      "Epoch 588/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1666 - acc: 0.9425\n",
      "Epoch 589/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1625 - acc: 0.9464\n",
      "Epoch 590/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1722 - acc: 0.9421\n",
      "Epoch 591/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1573 - acc: 0.9460\n",
      "Epoch 592/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1859 - acc: 0.9372\n",
      "Epoch 593/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1647 - acc: 0.9416\n",
      "Epoch 594/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1663 - acc: 0.9442\n",
      "Epoch 595/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1438 - acc: 0.9539\n",
      "Epoch 596/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1531 - acc: 0.9495\n",
      "Epoch 597/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1561 - acc: 0.9464\n",
      "Epoch 598/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1549 - acc: 0.9469\n",
      "Epoch 599/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1677 - acc: 0.9425\n",
      "Epoch 600/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1773 - acc: 0.9442\n",
      "Epoch 601/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1588 - acc: 0.9495\n",
      "Epoch 602/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1547 - acc: 0.9491\n",
      "Epoch 603/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1812 - acc: 0.9412\n",
      "Epoch 604/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1673 - acc: 0.9425\n",
      "Epoch 605/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1544 - acc: 0.9469\n",
      "Epoch 606/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1653 - acc: 0.9535\n",
      "Epoch 607/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1605 - acc: 0.9438\n",
      "Epoch 608/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1643 - acc: 0.9416\n",
      "Epoch 609/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1599 - acc: 0.9504\n",
      "Epoch 610/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1551 - acc: 0.9513\n",
      "Epoch 611/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1576 - acc: 0.9535\n",
      "Epoch 612/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1687 - acc: 0.9412\n",
      "Epoch 613/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1628 - acc: 0.9517\n",
      "Epoch 614/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1468 - acc: 0.9561\n",
      "Epoch 615/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1551 - acc: 0.9482\n",
      "Epoch 616/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1597 - acc: 0.9495\n",
      "Epoch 617/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1514 - acc: 0.9508\n",
      "Epoch 618/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1579 - acc: 0.9508\n",
      "Epoch 619/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1711 - acc: 0.9394\n",
      "Epoch 620/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1525 - acc: 0.9500\n",
      "Epoch 621/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1621 - acc: 0.9421\n",
      "Epoch 622/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1548 - acc: 0.9539\n",
      "Epoch 623/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1628 - acc: 0.9442\n",
      "Epoch 624/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1389 - acc: 0.9574\n",
      "Epoch 625/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1511 - acc: 0.9517\n",
      "Epoch 626/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1675 - acc: 0.9464\n",
      "Epoch 627/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1434 - acc: 0.9587\n",
      "Epoch 628/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1550 - acc: 0.9456\n",
      "Epoch 629/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1503 - acc: 0.9469\n",
      "Epoch 630/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1435 - acc: 0.9473\n",
      "Epoch 631/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1527 - acc: 0.9522\n",
      "Epoch 632/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1520 - acc: 0.9491\n",
      "Epoch 633/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1612 - acc: 0.9469\n",
      "Epoch 634/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1551 - acc: 0.9491\n",
      "Epoch 635/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1369 - acc: 0.9548\n",
      "Epoch 636/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1579 - acc: 0.9438\n",
      "Epoch 637/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1512 - acc: 0.9456\n",
      "Epoch 638/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1442 - acc: 0.9557\n",
      "Epoch 639/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1646 - acc: 0.9464\n",
      "Epoch 640/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1539 - acc: 0.9486\n",
      "Epoch 641/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1481 - acc: 0.9478\n",
      "Epoch 642/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1655 - acc: 0.9486\n",
      "Epoch 643/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1594 - acc: 0.9491\n",
      "Epoch 644/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1515 - acc: 0.9469\n",
      "Epoch 645/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1531 - acc: 0.9522\n",
      "Epoch 646/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1322 - acc: 0.9543\n",
      "Epoch 647/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1583 - acc: 0.9421\n",
      "Epoch 648/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1402 - acc: 0.9548\n",
      "Epoch 649/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1501 - acc: 0.9504\n",
      "Epoch 650/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1423 - acc: 0.9522\n",
      "Epoch 651/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1391 - acc: 0.9526\n",
      "Epoch 652/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1491 - acc: 0.9473\n",
      "Epoch 653/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1541 - acc: 0.9473\n",
      "Epoch 654/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1568 - acc: 0.9464\n",
      "Epoch 655/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1399 - acc: 0.9535\n",
      "Epoch 656/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1427 - acc: 0.9552\n",
      "Epoch 657/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1392 - acc: 0.9508\n",
      "Epoch 658/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1529 - acc: 0.9500\n",
      "Epoch 659/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1525 - acc: 0.9438\n",
      "Epoch 660/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1471 - acc: 0.9486\n",
      "Epoch 661/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1518 - acc: 0.9456\n",
      "Epoch 662/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1522 - acc: 0.9486\n",
      "Epoch 663/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1546 - acc: 0.9482\n",
      "Epoch 664/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1566 - acc: 0.9486\n",
      "Epoch 665/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1309 - acc: 0.9561\n",
      "Epoch 666/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1392 - acc: 0.9491\n",
      "Epoch 667/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1475 - acc: 0.9522\n",
      "Epoch 668/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1542 - acc: 0.9500\n",
      "Epoch 669/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1697 - acc: 0.9451\n",
      "Epoch 670/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1512 - acc: 0.9500\n",
      "Epoch 671/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1371 - acc: 0.9543\n",
      "Epoch 672/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1426 - acc: 0.9535\n",
      "Epoch 673/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1457 - acc: 0.9460\n",
      "Epoch 674/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1266 - acc: 0.9565\n",
      "Epoch 675/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1332 - acc: 0.9539\n",
      "Epoch 676/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1346 - acc: 0.9574\n",
      "Epoch 677/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1515 - acc: 0.9504\n",
      "Epoch 678/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1364 - acc: 0.9561\n",
      "Epoch 679/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1446 - acc: 0.9522\n",
      "Epoch 680/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1196 - acc: 0.9592\n",
      "Epoch 681/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1314 - acc: 0.9535\n",
      "Epoch 682/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1315 - acc: 0.9522\n",
      "Epoch 683/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1513 - acc: 0.9500\n",
      "Epoch 684/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1324 - acc: 0.9552\n",
      "Epoch 685/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1561 - acc: 0.9482\n",
      "Epoch 686/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1307 - acc: 0.9500\n",
      "Epoch 687/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1357 - acc: 0.9495\n",
      "Epoch 688/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1555 - acc: 0.9486\n",
      "Epoch 689/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1482 - acc: 0.9504\n",
      "Epoch 690/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1344 - acc: 0.9504\n",
      "Epoch 691/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1405 - acc: 0.9464\n",
      "Epoch 692/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1281 - acc: 0.9587\n",
      "Epoch 693/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1421 - acc: 0.9526\n",
      "Epoch 694/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1370 - acc: 0.9574\n",
      "Epoch 695/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1452 - acc: 0.9456\n",
      "Epoch 696/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1499 - acc: 0.9478\n",
      "Epoch 697/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1317 - acc: 0.9561\n",
      "Epoch 698/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1303 - acc: 0.9543\n",
      "Epoch 699/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1344 - acc: 0.9565\n",
      "Epoch 700/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1420 - acc: 0.9478\n",
      "Epoch 701/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1366 - acc: 0.9557\n",
      "Epoch 702/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1371 - acc: 0.9513\n",
      "Epoch 703/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1335 - acc: 0.9579\n",
      "Epoch 704/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1491 - acc: 0.9504\n",
      "Epoch 705/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1532 - acc: 0.9522\n",
      "Epoch 706/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1338 - acc: 0.9557\n",
      "Epoch 707/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1291 - acc: 0.9561\n",
      "Epoch 708/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1375 - acc: 0.9552\n",
      "Epoch 709/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1516 - acc: 0.9464\n",
      "Epoch 710/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1366 - acc: 0.9548\n",
      "Epoch 711/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1340 - acc: 0.9522\n",
      "Epoch 712/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1407 - acc: 0.9557\n",
      "Epoch 713/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1350 - acc: 0.9579\n",
      "Epoch 714/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1392 - acc: 0.9526\n",
      "Epoch 715/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1265 - acc: 0.9592\n",
      "Epoch 716/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1397 - acc: 0.9557\n",
      "Epoch 717/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1393 - acc: 0.9561\n",
      "Epoch 718/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1481 - acc: 0.9508\n",
      "Epoch 719/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1400 - acc: 0.9543\n",
      "Epoch 720/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1350 - acc: 0.9504\n",
      "Epoch 721/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1224 - acc: 0.9583\n",
      "Epoch 722/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1445 - acc: 0.9522\n",
      "Epoch 723/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1308 - acc: 0.9530\n",
      "Epoch 724/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1292 - acc: 0.9557\n",
      "Epoch 725/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1229 - acc: 0.9587\n",
      "Epoch 726/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1409 - acc: 0.9552\n",
      "Epoch 727/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1388 - acc: 0.9513\n",
      "Epoch 728/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1305 - acc: 0.9587\n",
      "Epoch 729/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1150 - acc: 0.9653\n",
      "Epoch 730/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1427 - acc: 0.9517\n",
      "Epoch 731/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1366 - acc: 0.9526\n",
      "Epoch 732/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1437 - acc: 0.9530\n",
      "Epoch 733/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1344 - acc: 0.9552\n",
      "Epoch 734/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1284 - acc: 0.9491\n",
      "Epoch 735/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1361 - acc: 0.9570\n",
      "Epoch 736/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1321 - acc: 0.9592\n",
      "Epoch 737/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1504 - acc: 0.9486\n",
      "Epoch 738/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1290 - acc: 0.9574\n",
      "Epoch 739/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1210 - acc: 0.9583\n",
      "Epoch 740/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1245 - acc: 0.9596\n",
      "Epoch 741/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1210 - acc: 0.9618\n",
      "Epoch 742/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1248 - acc: 0.9583\n",
      "Epoch 743/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1173 - acc: 0.9666\n",
      "Epoch 744/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1200 - acc: 0.9609\n",
      "Epoch 745/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1345 - acc: 0.9583\n",
      "Epoch 746/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1381 - acc: 0.9596\n",
      "Epoch 747/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1203 - acc: 0.9592\n",
      "Epoch 748/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1330 - acc: 0.9526\n",
      "Epoch 749/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1228 - acc: 0.9605\n",
      "Epoch 750/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1282 - acc: 0.9570\n",
      "Epoch 751/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1174 - acc: 0.9574\n",
      "Epoch 752/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1257 - acc: 0.9583\n",
      "Epoch 753/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1359 - acc: 0.9565\n",
      "Epoch 754/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1298 - acc: 0.9543\n",
      "Epoch 755/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1373 - acc: 0.9530\n",
      "Epoch 756/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1179 - acc: 0.9601\n",
      "Epoch 757/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1325 - acc: 0.9587\n",
      "Epoch 758/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1244 - acc: 0.9636\n",
      "Epoch 759/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1174 - acc: 0.9565\n",
      "Epoch 760/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1304 - acc: 0.9530\n",
      "Epoch 761/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1372 - acc: 0.9548\n",
      "Epoch 762/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1172 - acc: 0.9561\n",
      "Epoch 763/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1383 - acc: 0.9491\n",
      "Epoch 764/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1395 - acc: 0.9522\n",
      "Epoch 765/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1313 - acc: 0.9587\n",
      "Epoch 766/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1399 - acc: 0.9508\n",
      "Epoch 767/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1266 - acc: 0.9557\n",
      "Epoch 768/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1217 - acc: 0.9574\n",
      "Epoch 769/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1227 - acc: 0.9579\n",
      "Epoch 770/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.1220 - acc: 0.9539\n",
      "Epoch 771/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1239 - acc: 0.9574\n",
      "Epoch 772/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.1250 - acc: 0.9565\n",
      "Epoch 773/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1265 - acc: 0.9583\n",
      "Epoch 774/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1275 - acc: 0.9565\n",
      "Epoch 775/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1231 - acc: 0.9579\n",
      "Epoch 776/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1149 - acc: 0.9570\n",
      "Epoch 777/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.1231 - acc: 0.9570\n",
      "Epoch 778/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1178 - acc: 0.9618\n",
      "Epoch 779/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1203 - acc: 0.9579\n",
      "Epoch 780/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1276 - acc: 0.9535\n",
      "Epoch 781/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.1438 - acc: 0.9513\n",
      "Epoch 782/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1209 - acc: 0.9605\n",
      "Epoch 783/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1103 - acc: 0.9583\n",
      "Epoch 784/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.1395 - acc: 0.9504\n",
      "Epoch 785/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1315 - acc: 0.9539\n",
      "Epoch 786/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.1246 - acc: 0.9565\n",
      "Epoch 787/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1139 - acc: 0.9557\n",
      "Epoch 788/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1107 - acc: 0.9649\n",
      "Epoch 789/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1246 - acc: 0.9614\n",
      "Epoch 790/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1177 - acc: 0.9605\n",
      "Epoch 791/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.1155 - acc: 0.9574\n",
      "Epoch 792/800\n",
      "2278/2278 [==============================] - 8s 4ms/step - loss: 0.1267 - acc: 0.9561\n",
      "Epoch 793/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1238 - acc: 0.9530\n",
      "Epoch 794/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1264 - acc: 0.9548\n",
      "Epoch 795/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.1137 - acc: 0.9565\n",
      "Epoch 796/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1246 - acc: 0.9579\n",
      "Epoch 797/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1280 - acc: 0.9605\n",
      "Epoch 798/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.1252 - acc: 0.9548\n",
      "Epoch 799/800\n",
      "2278/2278 [==============================] - 9s 4ms/step - loss: 0.1117 - acc: 0.9601\n",
      "Epoch 800/800\n",
      "2278/2278 [==============================] - 10s 4ms/step - loss: 0.1110 - acc: 0.9662\n",
      "977/977 [==============================] - 1s 950us/step\n",
      "dict_keys(['loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Cross-Validation Accuracy of CNN training model 0.9252814739607008 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit model and Cross-Validation, Training Model 2 CONV + FULLY CONNECTED\n",
    "epochs = 800\n",
    "batch_size = 64\n",
    "CNN_model = CNN()\n",
    "history = CNN_model.fit(X_train, target_train, epochs=epochs, batch_size=batch_size)\n",
    "loss, accuracy = CNN_model.evaluate(X_test, target_test, verbose=1)\n",
    "\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['loss'])\n",
    "plt.title('The CNN model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Accuracy'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "print('\\nFinal Cross-Validation Accuracy of CNN training model', accuracy, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
