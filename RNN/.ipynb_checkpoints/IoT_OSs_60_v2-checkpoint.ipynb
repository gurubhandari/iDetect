{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load Libraries - Make sure to run this cell!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os\n",
    "from string import printable\n",
    "from sklearn import model_selection\n",
    "\n",
    "#import gensim\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, model_from_json, load_model\n",
    "from keras import regularizers\n",
    "from keras.layers.core import Dense, Dropout, Activation, Lambda, Flatten\n",
    "from keras.layers import Input, ELU, LSTM, Embedding, Convolution2D, MaxPooling2D, \\\n",
    "BatchNormalization, Convolution1D, MaxPooling1D, concatenate\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Deep Learning \n",
    "\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- tensorflow 1.4.1\n",
    "- keras 2.1.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>isMalicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>CHECK_PARAM   ( e2sxt -&gt; ets_timer !=  NULL )  ;</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>void bad  (  )    {  char * data ; char dataBu...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>staticvoid good2  (  )    {  if   ( 1 )   {   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>staticvoid good1  (  )    {  switch  ( 5 )   {...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>CWE415_Double_Free__malloc_free_char_84  {   b...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   code  isMalicious\n",
       "257    CHECK_PARAM   ( e2sxt -> ets_timer !=  NULL )  ;            5\n",
       "427   void bad  (  )    {  char * data ; char dataBu...           10\n",
       "2542  staticvoid good2  (  )    {  if   ( 1 )   {   ...            0\n",
       "2436  staticvoid good1  (  )    {  switch  ( 5 )   {...            0\n",
       "733   CWE415_Double_Free__malloc_free_char_84  {   b...           23"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load data code_snippet\n",
    "DATA_HOME = 'DL/'\n",
    "Final_Labeled_Dataset = pd.read_csv('Dataset of IoT OSs code - training.csv', encoding= 'unicode_escape')\n",
    "Final_Labeled_Dataset.sample(n=5).head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Labeled_Dataset.dropna(inplace=True)\n",
    "Final_Labeled_Dataset.drop_duplicates(inplace=True)\n",
    "Final_Labeled_Dataset.sample(n=5).head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Labeled_Dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_snippet_int_tokens = [[printable.index(x) + 1 for x in code_snippet if x in printable] \n",
    "                           for code_snippet in Final_Labeled_Dataset.code]\n",
    "max_len = 150\n",
    "X = sequence.pad_sequences(code_snippet_int_tokens, maxlen=max_len)\n",
    "target = np.array (Final_Labeled_Dataset.isMalicious)\n",
    "print('Matrix dimensions of X: ', X.shape, 'Vector dimension of target: ', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Cross-Validation: Split the data set into training and test data\n",
    "X_train, X_test, target_train, target_test = model_selection.train_test_split(X, target, test_size=0.30, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL get layer dimensions for any model!\n",
    "def print_layers_dims(model):\n",
    "    l_layers = model.layers\n",
    "    # Note None is ALWAYS batch_size\n",
    "    for i in range(len(l_layers)):\n",
    "        print(l_layers[i])\n",
    "        print('Input Shape: ', l_layers[i].input_shape, 'Output Shape: ', l_layers[i].output_shape)\n",
    "\n",
    "# GENERAL save model to disk function!\n",
    "def save_model(fileModelJSON,fileWeights):\n",
    "    #print(\"Saving model to disk: \",fileModelJSON,\"and\",fileWeights)\n",
    "    #have h5py installed\n",
    "    if Path(fileModelJSON).is_file():\n",
    "        os.remove(fileModelJSON)\n",
    "    json_string = model.to_json()\n",
    "    with open(fileModelJSON,'w' ) as f:\n",
    "        json.dump(json_string, f)\n",
    "    if Path(fileWeights).is_file():\n",
    "        os.remove(fileWeights)\n",
    "    model.save_weights(fileWeights)\n",
    "    \n",
    "\n",
    "# GENERAL load model from disk function!\n",
    "def load_model(fileModelJSON,fileWeights):\n",
    "    #print(\"Saving model to disk: \",fileModelJSON,\"and\",fileWeights)\n",
    "    with open(fileModelJSON, 'r') as f:\n",
    "         model_json = json.load(f)\n",
    "         model = model_from_json(model_json)\n",
    "    \n",
    "    model.load_weights(fileWeights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix dimensions of X:  (3708, 150) Vector dimension of target:  (3708,)\n"
     ]
    }
   ],
   "source": [
    "## Deep Learning model Definition --- A --- (Simple LSTM)\n",
    "\n",
    "\n",
    "def simple_lstm(max_len=150, emb_dim=32, max_vocab_len=100, lstm_output_size=32, W_reg=regularizers.l2(1e-4)):\n",
    "    # Input\n",
    "    main_input = Input(shape=(max_len,), dtype='int32', name='main_input')\n",
    "    # Embedding layer\n",
    "    emb = Embedding(input_dim=max_vocab_len, output_dim=emb_dim, input_length=max_len,\n",
    "                dropout=0.2, W_regularizer=W_reg)(main_input) \n",
    "\n",
    "    # LSTM layer\n",
    "    lstm = LSTM(lstm_output_size)(emb)\n",
    "    lstm = Dropout(0.5)(lstm)\n",
    "    \n",
    "    # Output layer (last fully connected layer)\n",
    "    output = Dense(54, activation='sigmoid', name='output')(lstm)\n",
    "\n",
    "    # Compile model and define optimizer\n",
    "    model = model(input=[main_input], output=[output])\n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model and Cross-Validation, Training Model 3 SIMPLE LSTM\n",
    "epochs = 800\n",
    "batch_size = 64\n",
    "RNN_model = simple_lstm()\n",
    "RNN_model.fit(X_train, target_train, epochs=epochs, batch_size=batch_size)\n",
    "loss, accuracy = RNN_model.evaluate(X_test, target_test, verbose=1)\n",
    "print('\\nFinal Cross-Validation Accuracy of RNN training model', accuracy, '\\n')\n",
    "print_layers_dims(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
